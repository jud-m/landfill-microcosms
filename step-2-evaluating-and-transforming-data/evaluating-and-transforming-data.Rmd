---
title: "Evaluating-data"
author: "Judy-Malas"
date: "12/23/2021"
output: 
  html_document: 
    theme: journal
---

This workflow is based on the 2018_ASM_Workshop by Scott A. Handley

Here is the forked repository: https://github.com/jud-m/2018_ASM_Workshop. 

In this workflow we will assess the data in our phyloseq objects and make sure it is ready for downstream visualization and statistics. 

* Inputs:
  + ps_all
  + vst_all 
  + ps_killed 
  +vst_killed 

* outputs:
  + ps_all.step2
  + vst_all.step2 
  + ps_all.rl
  + ps_all.prop
  + ps_killed.step2 
  + vst_killed.step2 
  + ps_killed.rl 
  + ps_killed.prop




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load packages
```{r load-packages, message=FALSE, warning=FALSE}

library(ggplot2)
library(gridExtra)
library(phyloseq)
require("tidyverse")
library("dplyr")
library("rmarkdown")
library("vegan")
library("PoiClaClu")
library("doParallel")
library("plotly")
library("microbiome")
library("ggpubr")
library("viridis")
library("plyr")
library("magrittr")
library("scales")
#library("data.table")
#library(grid)
#library(reshape2)
#library(randomForest)

```



## Load the input files

The input files for this part of the workflow are phyloseq objects such as those made in the `Making-phyloseq-objects` part of the workflow 
```{r inputfiles}

ps_all <- readRDS("~/landfill-microcosms/data/live_samples_objects/ps_all") # live samples 
vst_all <- readRDS("~/landfill-microcosms/data/live_samples_objects/vst_all") # live samples with transformed count table 
ps_killed <-readRDS("~/landfill-microcosms/data/killed_microcosms_objects/ps_killed") #killed samples 
vst_killed <-readRDS("~/landfill-microcosms/data/killed_microcosms_objects/vst_killed") #killed samples with transformed count table 

```
Make sure all of the files in the global environment are listed as "Large Phyloseq" (~2 MB or larger), if not, then your file didn't save correctly in the previous workflow, go back and re-save it then re-load here. 
It's possible that your file size will be smaller if you have fewer samples, but the most important thing is that when you open the object, you get the following:
```{r check-phyloseq-object}
ps_all
```
You should get a `phyloseq-class experiment-level object` with an `otu-table`, `sample_data`, `tax_table`, and `phy_tree()` (if a phylogentic tree was added)

#Tidying Data

## Factor re-ordering 

Here we have 4 groups; a control and four treatments (antibiotics, Fe(OH)3), and NA2SO4). 
R generally lists characters in alphabetical order, so any plot we make will list antibiotics first. We probably want the control listed first instead.
```{r, results= 'hide'}
#ps_all 
as.factor(sample_data(ps_all)$spike) #check the names of the levels
sample_data(ps_all)$spike <- factor(sample_data(ps_all)$spike, levels = c("Control ", "Antibiotics", "Fe(OH)3", "Na2SO4")) #ran into an issue because "Control " had a space at the end of it; R is senstive to spaces
levels(sample_data(ps_all)$spike) #check that your levels are in the order you want
sample_data(ps_all)$spike <- factor(sample_data(ps_all)$spike, labels = c("Control", "Antibiotics", "Fe(OH)3", "Na2SO4")) #remove the space
levels(sample_data(ps_all)$spike)

#repeat for all phyloseq objects

#vst_all
as.factor(sample_data(vst_all)$spike)
sample_data(vst_all)$spike <- factor(sample_data(ps_all)$spike, levels = c("Control ", "Antibiotics", "Fe(OH)3", "Na2SO4"))
sample_data(vst_all)$spike <- factor(sample_data(ps_all)$spike, labels = c("Control", "Antibiotics", "Fe(OH)3", "Na2SO4")) #remove the space
levels(sample_data(vst_all)$spike)

#ps_killed
as.factor(sample_data(ps_killed)$spike)
sample_data(ps_killed)$spike <- factor(sample_data(ps_killed)$spike, levels = c("killed_control", "Antibiotics","Fe(OH)3", "Na2SO4"))
levels(sample_data(ps_killed)$spike)
  
#vst_killed
as.factor(sample_data(vst_killed)$spike)
sample_data(ps_killed)$spike <- factor(sample_data(ps_killed)$spike, levels = c("killed_control", "Antibiotics","Fe(OH)3", "Na2SO4"))
levels(sample_data(ps_killed)$spike)


```

```{r taxa-columnname-relabeling}

newcolnames <- as.factor(c("Domain", "Phylum", "Class", "Order","Family" , "Genus",  "Species"))

colnames(tax_table(ps_all))  <- newcolnames

colnames(tax_table(ps_all))  #check that it worked


colnames(tax_table(vst_all)) <- newcolnames

colnames(tax_table(ps_killed)) <- newcolnames

colnames(tax_table(vst_killed)) <- newcolnames


colnames(tax_table(vst_all)) 

colnames(tax_table(ps_killed))

colnames(tax_table(vst_killed)) 


```

```{r checknosamples}

nsamples(ps_all)
nsamples(ps_killed)


```


Want to remove the "T6" sample from the killed phyloseq objects and make T7 = T6 so that both live and killed have the same number of samples
```{r remove-t7, results = 'hide'}

as_factor(sample_data(ps_killed)$sample_time)

ps_killed.rmt7 <- subset_samples(ps_killed, sample_time != "T6")

nsamples(ps_killed.rmt7)

#I don't care about the VST anymore
# vst_killed.rmt7 <-subset_samples(vst_killed, sample_time != "T6")
# as.character(sample_data(ps_killed.rmt7)$sample_time)


#now we need to rename T7 to T6

samdata_rmt7 <- ps_killed.rmt7@sam_data

samdata_rmt7 <- samdata_rmt7 %>%
  mutate(sample_time = case_when(sample_time == "T7" ~ "T6",
                                 TRUE ~ sample_time))

as.factor(samdata_rmt7$sample_time) #change back to a factor


```


```{r update-sampledata-killed}

sample_data(ps_killed.rmt7) = samdata_rmt7
#sample_data(vst_killed.rmt7) = samdata_rmt7
#put the updated sampled data in the phyloseq object


#update the phyloseq object 

ps_killed <- ps_killed.rmt7


```



# Evaluating Data 

There are several possible ways to evaluate the data, but a standard approach consists of the following

* Step 1) Evaluate Amplicon Sequence Variants (ASV) summary statistics
* Step 2) Detect & remove outlier samples
* Step 3) Taxon cleaning
* Step 4) Prevalence assesment & filtering


## Step 1) Evaluate Amplicon Sequence Variants (ASVs)

This part is only really relevant for the non-transformed phyloseq objects. The variance stabilizing transformation somehow re-combines the data so the ASVs in each sample are no longer accurate 

This chunk makes a data frame with 3 variables to count the number of ASVs in decreasing order
```{r make-df-of-ASV-sums}

readsumsdf.all <- data.frame(nreads = sort (taxa_sums(ps_all), decreasing = TRUE), # Create a new data frame of the sorted row sums,
                         sorted = 1:ntaxa(ps_all ), #a column of sorted values from 1 to the total number of individuals/counts for each ASV 
                        type = "ASVs" #a categorical variable stating these are all ASVs.
                         )

readsumsdf.killed <- data.frame(nreads = sort (taxa_sums(ps_killed), decreasing = TRUE), # Create a new data frame of the sorted row sums,
                         sorted = 1:ntaxa(ps_killed), #a column of sorted values from 1 to the total number of individuals/counts for each ASV 
                        type = "ASVs" #a categorical variable stating these are all ASVs.
                         )

```

```{r make-sample-sum-df}

# Make a data frame with a column for the read counts of each sample for histogram production
sample_sum_df.all <- data.frame(sum = sample_sums(ps_all))

sample_sum_df.killed <- data.frame (sum = sample_sums(ps_killed))

```

```{r number-seq-per-taxa}

# Generates a second bar plot with # of reads (y-axis) per sample. Sorted from most to least

ggplot(readsumsdf.all, aes(x = sorted, y = nreads)) +
  geom_bar(stat = "identity") +
  ggtitle("ASV Assessment") +
  scale_y_log10() +
  facet_wrap(~type, scales = "free") +
  ylab("# of Sequences")
  
ggplot(readsumsdf.killed, aes(x = sorted, y = nreads)) +
  geom_bar(stat = "identity") +
  ggtitle("ASV Assessment") +
  scale_y_log10() +
  facet_wrap(~type, scales = "free") +
  ylab("# of Sequences")


```

```{r histogram}

# Histogram of the number of Samples (y-axis) at various read depths

ggplot(sample_sum_df.all, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "firebrick3", binwidth = 150) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  ylab("# of Samples")

ggplot(sample_sum_df.killed, aes(x = sum)) + 
  geom_histogram(color = "black", fill = "firebrick3", binwidth = 150) +
  ggtitle("Distribution of sample sequencing depth") + 
  xlab("Read counts") +
  ylab("# of Samples")




```


```{r summary-stats-no-reads}

summary(sample_sums(ps_all)) 

summary(sample_sums(ps_killed)) 

sum(sample_sums(ps_all)) + sum(sample_sums(ps_killed))


```

The above data assessment is useful for getting an idea of 

1) the number of sequences per taxa. This will normally be a "long tail" with some taxa being highly abundant in the data tapering off to taxa with very few reads,

2) the number of reads per sample. 

Very low read count can be indicative of a failed reaction. 

Both of these plots will help give an understanding of how your data are structured across taxa and samples and will vary depending on the nature of your samples.




## Step 2) Detect outlier samples
```{r outlier-id-live, results = 'hide'}

#format a data table to combine summary data with sample variable data 
ss_all = sample_sums(ps_all)

sd_all = as.data.frame(sample_data(ps_all))

ss.dataf= merge(sd_all, data.frame("ASV" = ss_all), by="row.names")
ss.dataf

y= 1000 # set a thershold for th minimum number of acceptable reads, can start as a guess 
x= "sample_time" # the x-axis variable you want to examine 
label= "sample" 

#plot the data by the treatment variable 
ss_all_boxplot <- ggplot(ss.dataf, aes_string(x, y = "ASV", color = "spike")) + 
  geom_boxplot(outlier.colour="NA", position = position_dodge(width = 0.8)) +
  geom_jitter(size = 2, alpha = 0.6) +
  scale_y_log10() +
  facet_wrap(~spike) +
  geom_hline(yintercept = y, lty = 2) +
  geom_text(aes_string(label = label), size = 3, nudge_y = 0.05, nudge_x = 0.05)
ss_all_boxplot
#it looks like AB-T4 is an outlier in therms of ASVs 


```

```{r outlier-id-killed, results='hide'}

#do the same for killed samples
#format a data table to combine summary data with sample variable data 
ss_killed = sample_sums(ps_killed)
sd_killed = as.data.frame(sample_data(ps_killed))
ss_killed_df=  merge(sd_killed, data.frame("ASV" = ss_killed), by="row.names")
ss_killed_df   

y= 1000 # set a thershold for th minimum number of acceptable reads, can start as a guess 
x= "sample_time" # the x-axis variable you want to examine 
label= "sample" 


```

```{r killed-plot}

#plot the data by the treatment variable 

ss_killed_boxplot <- ggplot(ss_killed_df, aes_string(x, y = "ASV", color = "spike")) + 
  geom_boxplot(outlier.colour="NA", position = position_dodge(width = 0.8)) +
  geom_jitter(size = 2, alpha = 0.6) +
  scale_y_log10() +
  facet_wrap(~spike) +
  geom_hline(yintercept = y, lty = 2) +
  geom_text(aes_string(label = label), size = 3, nudge_y = 0.05, nudge_x = 0.05)
ss_killed_boxplot
#it looks like NK4-T1 is an outlier here 


```

The example data does have several samples with fewer than 1,000 ASV. 

When questionable samples arise you should take note of them so if there are samples which behave oddly in downstream analysis you can recall this information and perhaps justify their removal. In this case lets remove them for practice. 

Here it looks like NK5T1 and AB1T4 are outliers; maybe remove them? 
Here I made two new phyloseq objects called ps_all.rmout and ps_killed.rmout in which the outliers are removed, but the original ps objects are preserved. 
```{r}

nsamples(ps_all) #check how many samples are present
ps_all.outlier.retained <- ps_all # keep a copy of the phyloseq object that has an outlier
nsamples(ps_all.outlier.retained)

nsamples(ps_killed)
ps_killed.outlier.retained <- ps_killed


#remove outlier from live ps object
ps_all.rmout <- ps_all %>%
  subset_samples(
    bottle_number != "AB1t4")
nsamples(ps_all.rmout) #check that the sample was removed
ps_all <- ps_all.rmout #remove outlier from the original phyloseq object

#remove outlier from killed ps object
ps_killed.rmout <- ps_killed %>%
  subset_samples(
    bottle_number != "NK5t1")
nsamples(ps_killed.rmout)
ps_killed <- ps_killed.rmout  #remove outlier from the original phyloseq object





```


```{r}
nsamples(ps_all)
nsamples(ps_killed)
```



## Step 3) Taxon cleaning
Here is where we findout if there are some taxa that shouldn't be included in analysis, e.g. "Chloroplast / Cyanobacteria". 
However, since these are landfill samples, I decided to keep everything


```{r check-unique-taxa}

get_taxa_unique(ps_all, "Domain")
get_taxa_unique(ps_all, "Phylum")

get_taxa_unique(ps_killed, "Domain")
get_taxa_unique(ps_killed, "Phylum")

```


## Step 4) Prevalence assesment 
```{r}

#create a table for the number of features for each phyla

table(tax_table(ps_all)[, "Phylum"], exclude = NULL)

#compute prevalence of each feature + store as a data frome; defined as the number of samples in which taxa appears at least once
prev_all <- apply(X = otu_table(ps_all), MARGIN = ifelse(taxa_are_rows(ps_all), yes = 1, no = 2), FUN = function(x){sum(x > 0)})

#add taxonomy and total read counts to this data frame
prev_all  <- data.frame(Prevalence = prev_all, TotalAbundance = taxa_sums(ps_all), tax_table(ps_all)) 

plyr::ddply(prev_all, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})




```


```{r prevelance-plot}

#Dashed horizontal line is drawn at 5% prevalence level
#explore the relationship of prevalence and total read count for each feature 
prev_all1 = subset(prev_all, Phylum %in% get_taxa_unique(ps_all, "Phylum"))

ggplot(prev_all1, aes(TotalAbundance, Prevalence / nsamples(ps_all),color=Family)) +
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) + geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() + xlab("Total Abundance") + ylab("Prevalence [Frac of Live Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none") 
  
```



## Step 5) Prevalence filtering
This is how you filter if you wanted to filter at a certain prevalence. 
here I amke ps_all.5, in which taxa with a prevelance in <5% of samples is removed. 
```{r prevelance-filtering}
 nsamples(ps_all)
 prev_thres_all = 0.05 * nsamples(ps_all)
 prev_thres_all
 ntaxa(ps_all)

keepTaxa_all <- rownames(prev_all)[(prev_all$Prevalence >= prev_thres_all)]


 ps_all.5 = prune_taxa(keepTaxa_all, ps_all)
 ntaxa(ps_all.5)

 
 saveRDS(ps_all.5, "~/landfill-microcosms/data/live_samples_objects/ps_all.5")

ntaxa(ps_killed)


```


# Transforming Data


We can use the `transform_sample_counts` function to transform the data with the OTU tables of the phyloseq objects directly. 
We can do a variety of different transformations on the phyloseq object. 
The `vst_all` phyloseq object already has transformed counts, so we would only do these transformations on the ps_all phyloseq object, or the untransformed data. 

```{r data-transformations}

ps_all.rl <- transform_sample_counts(ps_all, function(OTU) OTU/sum(OTU)) #relative abundances 

ps_all.prop <- transform_sample_counts(ps_all, function(x) min(sample_sums(ps_all)) * x/sum(x))
                                       
ps_all.log <- transform_sample_counts(ps_all, function(x) log(1 + x))
                  

```


```{r view-transformations}

par(mfrow=c(1,4))

plot(sort(sample_sums(ps_all), TRUE), type = "o", main = "Native", ylab = "RSVs", xlab = "Samples")

plot(sort(sample_sums(ps_all.rl), TRUE), type = "o", main = "Relative Abundance", ylab = "RSVs", xlab = "Samples")

plot(sort(sample_sums(ps_all.prop), TRUE), type = "o", main = "Proportional Abundance", ylab = "RSVs", xlab = "Samples")

plot(sort(sample_sums(ps_all.log), TRUE), type = "o", main ="log Transformed" , ylab = "RSVs", xlab = "Samples")

par(mfrow=c(1,4))



```
RSVs = ASVs 

```{r view-histograms}

jpeg("~/landfill-microcosms/step-3-basic-data-vis/Figures/logtransformed_ps_all.jpg", width = 600, quality = 100)

p.nolog <- qplot(rowSums(otu_table(ps_all))) + ggtitle("Raw Counts") +
  theme_bw() +
  xlab("Row Sum") +
  ylab("# of Samples")

p.log <- qplot(log10(rowSums(otu_table(ps_all.log)))) +
  ggtitle("log10 transformed counts") +
  theme_bw() +
  xlab("Row Sum") +
  ylab("# of Samples")

ggarrange(p.nolog, p.log, ncol = 2, labels = c("A)", "B)"))

dev.off()


ggarrange(p.nolog, p.log, ncol = 2, labels = c("A)", "B)"))

```
These data are more normal without the log transformation.. 

```{r ps_killed_transformations}


ps_killed.rl <- transform_sample_counts(ps_killed, function(OTU) OTU/sum(OTU)) #relative abundances 

ps_killed.prop <- transform_sample_counts(ps_killed, function(x) min(sample_sums(ps_all)) * x/sum(x))
                                       
ps_killed.log <- transform_sample_counts(ps_killed, function(x) log(1 + x))


jpeg("~/landfill-microcosms/step-3-basic-data-vis/Figures/logtransformed_ps_killed.jpg", width = 600, quality = 100)

p.nolog.killed <- qplot(rowSums(otu_table(ps_killed))) + ggtitle("Raw Counts") +
  theme_bw() +
  xlab("Row Sum") +
  ylab("# of Samples")

p.log.killed <- qplot(log10(rowSums(otu_table(ps_killed.log)))) +
  ggtitle("log10 transformed counts") +
  theme_bw() +
  xlab("Row Sum") +
  ylab("# of Samples")

ggarrange(p.nolog.killed, p.log.killed, ncol = 2, labels = c("A)", "B)"))

dev.off()

ggarrange(p.nolog.killed, p.log.killed, ncol = 2, labels = c("A)", "B)"))



```
These are not normal either way 




#save all objects to take to the next step 

* outputs:
  + ps_all.step2
  + vst_all.step2 
  + ps_all.rl
  + ps_all.prop
  + ps_killed.step2 
  + vst_killed.step2 
  + ps_killed.rl 
  + ps_killed.prop

```{r save-new-phyloseq-objects}

# live samples 

saveRDS(ps_all, "~/landfill-microcosms/data/live_samples_objects/ps_all.step2") 

saveRDS(ps_all.rmout, "~/landfill-microcosms/data/live_samples_objects/ps_all.rmout") #outlier removed

saveRDS(vst_all, "~/landfill-microcosms/data/live_samples_objects/vst_all.step2")


saveRDS(ps_all.rl, "~/landfill-microcosms/data/live_samples_objects/ps_all.rl") 

saveRDS(ps_all.prop, "~/landfill-microcosms/data/live_samples_objects/ps_all.prop") 




 #killed samples 

saveRDS(ps_killed, "~/landfill-microcosms/data/killed_microcosms_objects/ps_killed.step2")

saveRDS(ps_killed.rmout, "~/landfill-microcosms/data/killed_microcosms_objects/ps_killed.rmout")

saveRDS(vst_killed, "~/landfill-microcosms/data/killed_microcosms_objects/vst_killed.step2")

saveRDS(ps_killed.rl, "~/landfill-microcosms/data/killed_microcosms_objects/ps_killed.rl")

saveRDS(ps_killed.prop, "~/landfill-microcosms/data/killed_microcosms_objects/ps_killed.prop")

```



